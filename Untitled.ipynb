{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "import numpy as np\n",
    "import load_data\n",
    "import os\n",
    "import numpy as np\n",
    "import imageio \n",
    "import cv2"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def pdf_sampling(bins, weights, N_samples, det=False):\n",
    "    # Get pdf\n",
    "    weights += 1e-5  # prevent nans\n",
    "    pdf = weights / np.reduce_sum(weights, -1, keepdims=True)\n",
    "    cdf = np.cumsum(pdf, -1)\n",
    "    cdf = np.concat([np.zeros_like(cdf[..., :1]), cdf], -1)\n",
    "\n",
    "    # Take uniform samples\n",
    "    if det:\n",
    "        u = np.linspace(0., 1., N_samples)\n",
    "        u = np.broadcast_to(u, list(cdf.shape[:-1]) + [N_samples])\n",
    "    else:\n",
    "        u = np.random.uniform(list(cdf.shape[:-1]) + [N_samples])\n",
    "\n",
    "    # Invert CDF\n",
    "    inds = np.searchsorted(cdf, u, side='right')\n",
    "    below = np.maximum(0, inds-1)\n",
    "    above = np.minimum(cdf.shape[-1]-1, inds)\n",
    "    inds_g = np.stack([below, above], -1)\n",
    "    cdf_g = np.gather(cdf, inds_g, axis=-1, batch_dims=len(inds_g.shape)-2)\n",
    "    bins_g = np.gather(bins, inds_g, axis=-1, batch_dims=len(inds_g.shape)-2)\n",
    "\n",
    "    denom = (cdf_g[..., 1]-cdf_g[..., 0])\n",
    "    denom = np.where(denom < 1e-5, np.ones_like(denom), denom)\n",
    "    t = (u-cdf_g[..., 0])/denom\n",
    "    samples = bins_g[..., 0] + t * (bins_g[..., 1]-bins_g[..., 0])\n",
    "\n",
    "    return samples"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "np.loadtxt('/home/erl/yaw/cse291-nerf/data/bottles/pose/2_test_0186.txt')"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[-6.44217893e-01,  7.60223269e-01, -8.39290850e-02,\n",
       "         2.51788266e-01],\n",
       "       [ 7.64842142e-01,  6.40327464e-01, -7.06929050e-02,\n",
       "         2.12078326e-01],\n",
       "       [-3.00000000e-07, -1.09734122e-01, -9.93960977e-01,\n",
       "         2.98188263e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         1.00000000e+00]])"
      ]
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "def load_data(basedir= \"data/bottles\", res=1):\n",
    "    counts = []\n",
    "    imgs = [[],[]]\n",
    "    poses = [[],[]]\n",
    "    img_root = os.path.join(basedir, \"rgb\")\n",
    "    pose_root = os.path.join(basedir, \"pose\")\n",
    "    for filename in os.listdir(img_root):\n",
    "        print(filename)\n",
    "        print(os.path.join(basedir, \"rgb\"))\n",
    "        data_name = filename.split('.')[0]\n",
    "        img = imageio.imread(os.path.join(img_root, filename))\n",
    "        img = (np.array(img) / 255.).astype(np.float32)\n",
    "        pose = np.loadtxt(os.path.join(pose_root, data_name+\".txt\"))\n",
    "        index = int(data_name[0])\n",
    "        imgs[index].append(img)\n",
    "        poses[index].append(pose)\n",
    "\n",
    "    counts[0] = len(imgs[0])\n",
    "    counts[1] = len(imgs[1])\n",
    "    imgs = np.concatenate(imgs, 0)\n",
    "    poses = np.concatenate(poses, 0)\n",
    "\n",
    "    \n",
    "    H, W = imgs[0].shape[:2]\n",
    "    focal = 875.\n",
    "    K = [[875., 0., 400.],\n",
    "        [0., 875., 400.],\n",
    "        [0., 0., 1.]]\n",
    "    print(f\"Focal: {focal}\")\n",
    "        \n",
    "    H = H//res\n",
    "    W = W//res\n",
    "    focal = focal/res\n",
    "\n",
    "    for i, img in enumerate(imgs):\n",
    "        img[i] = cv2.resize(img, (W, H), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    return imgs, poses, [H, W, focal], K"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "import imageio\n",
    "import json\n",
    "import random\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from run_nerf_helpers import *\n",
    "\n",
    "from load_llff import load_llff_data\n",
    "from load_deepvoxels import load_dv_data\n",
    "from load_blender import load_blender_data\n",
    "from load_LINEMOD import load_LINEMOD_data\n",
    "\n",
    "from load_data import load_data\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "np.random.seed(0)\n",
    "DEBUG = False\n",
    "\n",
    "\n",
    "def create_nerf(args):\n",
    "    \"\"\"Instantiate NeRF's MLP model.\n",
    "    \"\"\"\n",
    "    embed_fn, input_ch = get_embedder(args.multires, args.i_embed)\n",
    "\n",
    "    input_ch_views = 0\n",
    "    embeddirs_fn = None\n",
    "    if args.use_viewdirs:\n",
    "        embeddirs_fn, input_ch_views = get_embedder(args.multires_views, args.i_embed)\n",
    "    output_ch = 5 if args.N_importance > 0 else 4\n",
    "    skips = [4]\n",
    "    model = NeRF(D=args.netdepth, W=args.netwidth,\n",
    "                 input_ch=input_ch, output_ch=output_ch, skips=skips,\n",
    "                 input_ch_views=input_ch_views, use_viewdirs=args.use_viewdirs).to(device)\n",
    "    grad_vars = list(model.parameters())\n",
    "\n",
    "    model_fine = None\n",
    "    if args.N_importance > 0:\n",
    "        model_fine = NeRF(D=args.netdepth_fine, W=args.netwidth_fine,\n",
    "                          input_ch=input_ch, output_ch=output_ch, skips=skips,\n",
    "                          input_ch_views=input_ch_views, use_viewdirs=args.use_viewdirs).to(device)\n",
    "        grad_vars += list(model_fine.parameters())\n",
    "\n",
    "    network_query_fn = lambda inputs, viewdirs, network_fn : run_network(inputs, viewdirs, network_fn,\n",
    "                                                                embed_fn=embed_fn,\n",
    "                                                                embeddirs_fn=embeddirs_fn,\n",
    "                                                                netchunk=args.netchunk)\n",
    "\n",
    "    # Create optimizer\n",
    "    optimizer = torch.optim.Adam(params=grad_vars, lr=args.lrate, betas=(0.9, 0.999))\n",
    "\n",
    "    start = 0\n",
    "    basedir = args.basedir\n",
    "    expname = args.expname\n",
    "\n",
    "    ##########################\n",
    "\n",
    "    # Load checkpoints\n",
    "    if args.ft_path is not None and args.ft_path!='None':\n",
    "        ckpts = [args.ft_path]\n",
    "    else:\n",
    "        ckpts = [os.path.join(basedir, expname, f) for f in sorted(os.listdir(os.path.join(basedir, expname))) if 'tar' in f]\n",
    "\n",
    "    print('Found ckpts', ckpts)\n",
    "    if len(ckpts) > 0 and not args.no_reload:\n",
    "        ckpt_path = ckpts[-1]\n",
    "        print('Reloading from', ckpt_path)\n",
    "        ckpt = torch.load(ckpt_path)\n",
    "\n",
    "        start = ckpt['global_step']\n",
    "        optimizer.load_state_dict(ckpt['optimizer_state_dict'])\n",
    "\n",
    "        # Load model\n",
    "        model.load_state_dict(ckpt['network_fn_state_dict'])\n",
    "        if model_fine is not None:\n",
    "            model_fine.load_state_dict(ckpt['network_fine_state_dict'])\n",
    "\n",
    "    ##########################\n",
    "\n",
    "    render_kwargs_train = {\n",
    "        'network_query_fn' : network_query_fn,\n",
    "        'perturb' : args.perturb,\n",
    "        'N_importance' : args.N_importance,\n",
    "        'network_fine' : model_fine,\n",
    "        'N_samples' : args.N_samples,\n",
    "        'network_fn' : model,\n",
    "        'use_viewdirs' : args.use_viewdirs,\n",
    "        'white_bkgd' : args.white_bkgd,\n",
    "        'raw_noise_std' : args.raw_noise_std,\n",
    "    }\n",
    "\n",
    "    # NDC only good for LLFF-style forward facing data\n",
    "    if args.dataset_type != 'llff' or args.no_ndc:\n",
    "        print('Not ndc!')\n",
    "        render_kwargs_train['ndc'] = False\n",
    "        render_kwargs_train['lindisp'] = args.lindisp\n",
    "\n",
    "    render_kwargs_test = {k : render_kwargs_train[k] for k in render_kwargs_train}\n",
    "    render_kwargs_test['perturb'] = False\n",
    "    render_kwargs_test['raw_noise_std'] = 0.\n",
    "\n",
    "    return render_kwargs_train, render_kwargs_test, start, grad_vars, optimizer\n",
    "\n",
    "\n",
    "def raw2outputs(raw, z_vals, rays_d, raw_noise_std=0, white_bkgd=False, pytest=False):\n",
    "    \"\"\"Transforms model's predictions to semantically meaningful values.\n",
    "    Args:\n",
    "        raw: [num_rays, num_samples along ray, 4]. Prediction from model.\n",
    "        z_vals: [num_rays, num_samples along ray]. Integration time.\n",
    "        rays_d: [num_rays, 3]. Direction of each ray.\n",
    "    Returns:\n",
    "        rgb_map: [num_rays, 3]. Estimated RGB color of a ray.\n",
    "        disp_map: [num_rays]. Disparity map. Inverse of depth map.\n",
    "        acc_map: [num_rays]. Sum of weights along each ray.\n",
    "        weights: [num_rays, num_samples]. Weights assigned to each sampled color.\n",
    "        depth_map: [num_rays]. Estimated distance to object.\n",
    "    \"\"\"\n",
    "    raw2alpha = lambda raw, dists, act_fn=F.relu: 1.-torch.exp(-act_fn(raw)*dists)\n",
    "\n",
    "    dists = z_vals[...,1:] - z_vals[...,:-1]\n",
    "    dists = torch.cat([dists, torch.Tensor([1e10]).expand(dists[...,:1].shape)], -1)  # [N_rays, N_samples]\n",
    "\n",
    "    dists = dists * torch.norm(rays_d[...,None,:], dim=-1)\n",
    "\n",
    "    rgb = torch.sigmoid(raw[...,:3])  # [N_rays, N_samples, 3]\n",
    "    noise = 0.\n",
    "    if raw_noise_std > 0.:\n",
    "        noise = torch.randn(raw[...,3].shape) * raw_noise_std\n",
    "\n",
    "        # Overwrite randomly sampled data if pytest\n",
    "        if pytest:\n",
    "            np.random.seed(0)\n",
    "            noise = np.random.rand(*list(raw[...,3].shape)) * raw_noise_std\n",
    "            noise = torch.Tensor(noise)\n",
    "\n",
    "    alpha = raw2alpha(raw[...,3] + noise, dists)  # [N_rays, N_samples]\n",
    "    # weights = alpha * tf.math.cumprod(1.-alpha + 1e-10, -1, exclusive=True)\n",
    "    weights = alpha * torch.cumprod(torch.cat([torch.ones((alpha.shape[0], 1)), 1.-alpha + 1e-10], -1), -1)[:, :-1]\n",
    "    rgb_map = torch.sum(weights[...,None] * rgb, -2)  # [N_rays, 3]\n",
    "\n",
    "    depth_map = torch.sum(weights * z_vals, -1)\n",
    "    disp_map = 1./torch.max(1e-10 * torch.ones_like(depth_map), depth_map / torch.sum(weights, -1))\n",
    "    acc_map = torch.sum(weights, -1)\n",
    "\n",
    "    if white_bkgd:\n",
    "        rgb_map = rgb_map + (1.-acc_map[...,None])\n",
    "\n",
    "    return rgb_map, disp_map, acc_map, weights, depth_map\n",
    "\n",
    "def train():\n",
    "\n",
    "    # Load data\n",
    "    K = None\n",
    "\n",
    "    images, poses, hwf, K = load_data()\n",
    "    # Cast intrinsics to right types\n",
    "    H, W, focal = hwf\n",
    "    H, W = int(H), int(W)\n",
    "    hwf = [H, W, focal]\n",
    "\n",
    "    # Create nerf model\n",
    "    render_kwargs_train, render_kwargs_test, start, grad_vars, optimizer = create_nerf()\n",
    "    global_step = start\n",
    "\n",
    "    # Prepare raybatch tensor if batching random rays\n",
    "    N_rand = args.N_rand\n",
    "    use_batching = not args.no_batching\n",
    "    if use_batching:\n",
    "        # For random ray batching\n",
    "        print('get rays')\n",
    "        rays = np.stack([get_rays_np(H, W, K, p) for p in poses[:,:3,:4]], 0) # [N, ro+rd, H, W, 3]\n",
    "        print('done, concats')\n",
    "        rays_rgb = np.concatenate([rays, images[:,None]], 1) # [N, ro+rd+rgb, H, W, 3]\n",
    "        rays_rgb = np.transpose(rays_rgb, [0,2,3,1,4]) # [N, H, W, ro+rd+rgb, 3]\n",
    "        rays_rgb = np.stack([rays_rgb[i] for i in i_train], 0) # train images only\n",
    "        rays_rgb = np.reshape(rays_rgb, [-1,3,3]) # [(N-1)*H*W, ro+rd+rgb, 3]\n",
    "        rays_rgb = rays_rgb.astype(np.float32)\n",
    "        print('shuffle rays')\n",
    "        np.random.shuffle(rays_rgb)\n",
    "\n",
    "        print('done')\n",
    "        i_batch = 0\n",
    "\n",
    "    # Move training data to GPU\n",
    "    if use_batching:\n",
    "        images = torch.Tensor(images).to(device)\n",
    "    poses = torch.Tensor(poses).to(device)\n",
    "    if use_batching:\n",
    "        rays_rgb = torch.Tensor(rays_rgb).to(device)\n",
    "\n",
    "\n",
    "    N_iters = 200000 + 1\n",
    "    \n",
    "    start = start + 1\n",
    "    for i in trange(start, N_iters):\n",
    "        time0 = time.time()\n",
    "\n",
    "\n",
    "        batch = rays_rgb[i_batch:i_batch+N_rand] # [B, 2+1, 3*?]\n",
    "        batch = torch.transpose(batch, 0, 1)\n",
    "        batch_rays, target_s = batch[:2], batch[2]\n",
    "\n",
    "        i_batch += N_rand\n",
    "        if i_batch >= rays_rgb.shape[0]:\n",
    "            print(\"Shuffle data after an epoch!\")\n",
    "            rand_idx = torch.randperm(rays_rgb.shape[0])\n",
    "            rays_rgb = rays_rgb[rand_idx]\n",
    "            i_batch = 0\n",
    "\n",
    "        #####  Core optimization loop  #####\n",
    "        rgb, disp, acc, extras = render(H, W, K, chunk=args.chunk, rays=batch_rays,\n",
    "                                                verbose=i < 10, retraw=True,\n",
    "                                                **render_kwargs_train)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        img_loss = img2mse(rgb, target_s)\n",
    "        trans = extras['raw'][...,-1]\n",
    "        loss = img_loss\n",
    "        psnr = mse2psnr(img_loss)\n",
    "\n",
    "        if 'rgb0' in extras:\n",
    "            img_loss0 = img2mse(extras['rgb0'], target_s)\n",
    "            loss = loss + img_loss0\n",
    "            psnr0 = mse2psnr(img_loss0)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        global_step += 1\n",
    "\n",
    "\n",
    "if __name__=='__main__':\n",
    "    torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "\n",
    "    train()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "def stratified_sampling(t_n, t_f, N):\n",
    "    diff = t_f - t_n\n",
    "    randoms = np.random.uniform(0, diff/N, N)\n",
    "    print (randoms)\n",
    "    results = np.linspace(t_n, t_f, N, dtype = np.float32)\n",
    "    print (results)\n",
    "    results += randoms\n",
    "    return results"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def pdf_sampling(bins, weights, N_samples, det=False):\n",
    "    # Get pdf\n",
    "    weights += 1e-5  # prevent nans\n",
    "    pdf = weights / tf.reduce_sum(weights, -1, keepdims=True)\n",
    "    cdf = tf.cumsum(pdf, -1)\n",
    "    cdf = tf.concat([tf.zeros_like(cdf[..., :1]), cdf], -1)\n",
    "\n",
    "    # Take uniform samples\n",
    "    if det:\n",
    "        u = tf.linspace(0., 1., N_samples)\n",
    "        u = tf.broadcast_to(u, list(cdf.shape[:-1]) + [N_samples])\n",
    "    else:\n",
    "        u = tf.random.uniform(list(cdf.shape[:-1]) + [N_samples])\n",
    "\n",
    "    # Invert CDF\n",
    "    inds = tf.searchsorted(cdf, u, side='right')\n",
    "    below = tf.maximum(0, inds-1)\n",
    "    above = tf.minimum(cdf.shape[-1]-1, inds)\n",
    "    inds_g = tf.stack([below, above], -1)\n",
    "    cdf_g = tf.gather(cdf, inds_g, axis=-1, batch_dims=len(inds_g.shape)-2)\n",
    "    bins_g = tf.gather(bins, inds_g, axis=-1, batch_dims=len(inds_g.shape)-2)\n",
    "\n",
    "    denom = (cdf_g[..., 1]-cdf_g[..., 0])\n",
    "    denom = tf.where(denom < 1e-5, tf.ones_like(denom), denom)\n",
    "    t = (u-cdf_g[..., 0])/denom\n",
    "    samples = bins_g[..., 0] + t * (bins_g[..., 1]-bins_g[..., 0])\n",
    "\n",
    "    return samples"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "def volume_rendering(start, end, N, F):\n",
    "    start = np.array(start).reshape([1,3])\n",
    "    end = np.array(end).reshape([1,3])\n",
    "    t = np.norm(end - start)\n",
    "    ts = stratified_sampling(0, t, N)\n",
    "    d = (end - start)/t\n",
    "    sample_points = []\n",
    "    for s in ts:\n",
    "        sample_points.append(start + s*d)\n",
    "    sample_points = np.array(sample_points)\n",
    "\n",
    "    density, color = F(sample_points)\n",
    "    density = np.array(density).reshape([N,])\n",
    "    color = np.array(color).reshape([N,])\n",
    "\n",
    "    delta_d = np.diff(ts)\n",
    "    color_d = color[0,:-1]\n",
    "    sum_t_color = -np.cumsum(delta_d*color_d)\n",
    "    T = np.exp(sum_t_color)\n",
    "    T = np.concatenate(([0.],T))\n",
    "    delta_d = np.concatenate(([0.], delta_d))\n",
    "\n",
    "    return np.sum(T*(1 - np.exp(-delta_d))*color)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "import numpy as np\n",
    "def encoder_position(X, Dims):\n",
    "    positions = [X]\n",
    "    for i in range(Dims):\n",
    "        for fn in [np.sin, np.cos]:\n",
    "            positions.append(fn(2.0 ** i * X))\n",
    "    return np.concatenate(positions, axis= 0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "X = np.ones([3,4])\n",
    "X[:,0] = 0\n",
    "encoder_position(X, 10).shape\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(63, 4)"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_rays(H, W, focal, c2w):\n",
    "    i, j = np.meshgrid(np.arange(W, dtype=np.float32),\n",
    "                       np.arange(H, dtype=np.float32), indexing='xy')\n",
    "    dirs = np.stack([(i-W*.5)/focal, -(j-H*.5)/focal, -np.ones_like(i)], -1)\n",
    "    rays_d = np.sum(dirs[..., np.newaxis, :] * c2w[:3, :3], -1)\n",
    "    rays_o = np.broadcast_to(c2w[:3, -1], np.shape(rays_d))\n",
    "    return rays_o, rays_d"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "x, y = get_rays(1, 1, 1, np.ones([4,4]))\n",
    "x, y"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(array([[[1., 1., 1.]]]), array([[[-1., -1., -1.]]]))"
      ]
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.7 64-bit ('ml3d': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "interpreter": {
   "hash": "c6662b505d7849ed570b528763760c6498d5b7aea63f57f2e051701480332ba5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}